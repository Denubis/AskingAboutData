\startcomponent c_7_db
\product prd_Chapter7
\project project_thesis

\chapter{Different Realities of Data and the Database}

How can different realities of data can be applied to the philosophical conceptions of the database as corporate memory? Different realities of data provide a novel and interesting context in which to think about corporate databases and database design. To a database, data is an instantiation of a sign. Just as words represent both signs and reality, tuples\footnote{A tuple is a more formal name for \quotation{row} in a database, or a set of data of different domains stored together.} in a database represent signs and the reality behind those signs. When we define data as an instantiated sign, the nature of data in a database becomes very important. Using the communicative definition of data, a database contains a number of signs and the explicitly encoded relationships between the tuples.

In relational databases, there exist two categories of relationships between tuples. The first, and simplest, is a grouping of tuples into tables. A table exists as a set of identically formatted tuples representing different data of similar type. The second type of relationship between tuples is relationships between tables: while tables group tuples together, tuples can relate to each other based on internal codes or information.

The combination of these relationships allows for the computer to encode signs as data in the form of tuples and to relate signs to each O, allowing for manipulation of the signs to create new signs, and for information processing to occur outside the brain. In database design, the term \quotation{business rule}\footnote{A business rule is a constraint or action imposed upon the database by the business reality within which the database is functioning.
} defines a statement that shapes the nature of the database or the way the database manipulates information.

From a semiotic perspective, we can interpret these business rules as mental maps: they exist to shape, form, and interpret the data through our understanding of the local reality of business practices and norms. Through business rules interpreting data, the computer can act on the data, pass new data to other business rules, or change the business rules themselves: the exact same relationship that a mental map has with signs in a conscious system, albeit on a much more simplified level.

The act of designing a database is strongly informed by the designer's constructions of data. The mapping of relationships and the nature of each table is a reflection on both how the designer understands data and how the designer understands how the ultimate users understand their data.

\section{Case Study}
Consider a case of a fictitious winery trying to create a data warehouse. I will use this as a case study in which the ramifications of realities of data are illustrated in this chapter. This case study was developed for a data warehousing course at my old university and is of sufficient complexity to illustrate some of the issues raised in this chapter.

\startextract
TigerWine Distributors was founded in 1985 by two college friends, Miss G. and Mr. R. The company was originally based on a small family winery, founded in 1878
and passed down through Miss G’s family, and has since grown into a very successful wine
distribution company. Today, the original winery is only a small portion of their business.
The California based company now trades as an importer and distributor of
wines throughout the United States. Over the years, TigerWine Distributors has built up an
extensive portfolio of premium products and represents a large number of national and
international wine wholesalers as well as many small vintners.

One of the greatest strengths of TigerWine Distributors is that it has contacts with the complete
spectrum of the wine-sales trade from small, but prestigious, restaurants to the largest liquor
stores and supermarkets. Their customers also include private individuals, regional vintners,
traditional wholesalers, individual cash-and-carries, specialty stores, and other independent
outlets.
\stopextract

This setup is an excellent foil, as the hereditary views of Miss G’s understanding of data as tempered by her university experience could quite plausibly differ from Mr. R’s understanding, especially if Miss G studied a more scientific viticulture major versus’s R’s business degree. If these managers commission an analytic data warehouse for their distribution business, it is reasonable to suppose that they will understand data in different ways. To these two individuals, we will add a third, a Mrs. B, who is their Chief Technical Officer and the person developing their data warehouse.

For purposes of this case study, Miss G considers data to be reflections of objective reality, most comfortable manipulating data as observations from chemical studies of grape biology. While she admits that there is business data to be collected and analyzed, the data exist only in sales records: the movement of real things and the income derived from their movement.

Mr. R considers the most important \quotation{data} in their records to be the intangibles of customer satisfaction and error rates. He has heard that the data warehouse could explore these questions but is not entirely sure what black magic needs to be applied to the \quotation{big data} for that exploration to occur. In many ways, Mr. R considers data to be encoded human communications and is interested in how to decode those communications.

Mrs. B is the CTO, and therefore considers all data to be subjective recorded impressions. While she considers this in her role, she also needs to design the database so it can fulfill the requirements of the other two founders of the company. For purposes of this case study, Mrs. B will be making a data warehouse that only covers the distribution side of the company, and will be trying to understand the realities of data held by the founders.

Designers can encode business rules in a database in two ways. First, designers can build them into the design of the system, informing the grouping of columns, the design of tables, and the relationship of one table to another. Relationships are a way of encoding the constraints of reality into a constructed simulacrum, a database. A constraint is a database's way of enforcing a rule. A relationship between tuples is defined as: \quotation{this tuple may not exist without a reference to another extant tuple.} This both encodes the specific tuple the entity being created relates to, and enforces articulation of that relationship.

In the context of TigerWine Distribution, the table business rules look like:

\startextract
CASE

A collection of items offered for sale; this is the fundamental unit
of sale for the distribution side of the business. It can be:
- a case of wine that is not on a special promotion (case-wine)
- a case of wine that is on a special promotion (promotion-case)
- a special promotion package that consists of one or more bottles
of wine and one or more other items. (promotion-case)
\stopextract

This is a straightforward and unambiguous presentation of what the table contains that would be accepted by any of the realities of data. The practice of the different realities does not rely on the different formulation of specific business rules, but the very choice of specification of the rules.

Therefore, for purposes of the case study, the question is to illustrate a table or relationship that each of the three understandings would find particularly compelling or distasteful. For data as objective measurements, Miss G would find the presence of a table of written employee evaluations without any real \quotation{data} to back it up most objectionable. It would illustrate the worst of subjectivity, without even offering the benefits that computerized semantic analysis of a mass of product reviews. The tables she would most approve of would be the automated sensor readings from the distribution warehouses of the stock that was on each shelf. Miss G would also object to normalization because it splits one \quotation{observation} across multiple tables; as the meta-data for the observation belongs in a different table than the data.

Mr. R as someone who holds data as subjective observations, is nominally "okay" with \quotation{anything} in the database, so long as it accurately reflects reality. Mr. R is not interested in the merits or lack thereof of normalization, so long as the database accurately reflects the subjective impressions of reality that he wants it to encode. In a way, this means that Mr. R treats all entities within the database as \quotation{equal data} with no one tuple privileged against any other due to its intrinsic truth or relationship to the universe. Mr R especially dislikes tables that are not internally consistent within the rules of the database: just because reality gives people multiple phone numbers does not mean that there should be multiple phone number fields in the \quotation{person} table, even after the fact. For Mr R, if reality changes, the database should be reengineered to reflect that reality accurately without consideration for the costs or impacts on established software. Without a consistent and useful database structure, the queries to manipulate and transform the presentation of data in the database will fail.

Mrs. B considers data to be encoded human communications or encoded information. Therefore, the database tables are a repository of human interactions with the world, curated and made searchable by other humans. Any design that interferes with that curation is discouraged, as it makes the task of the maintainer that much more difficult. Because the tables in a database have on ontological value to Mrs B, she is comfortable with whatever arrangement of tables that will work best with the programs that support human communication. Any table arrangement that exists for the data’s sake rather than to support the programs that support human communication is pointless and wasteful effort. For example, normalized relations that introduce inefficiencies for the purpose of avoiding rare or even purely theoretical data anomalies is to be fiercely resisted: it is inefficient and does not serve human communication. Instead, it gets in the way of programmers and therefore makes the encoded data less likely to be presented to the users.

The O, more significant way, is with queries\footnote{A query is a way of retrieving sets of tuples from the database. }: exposing and relating signs in a predetermined format. The real power of queries, however, is that the data they output can be used as the inputs for subsequent queries: just like a sign or group of signs, one mental model can output data to another mental model for further interpretation. A query draws upon the encoded business rules in the database and applies some criteria to find only interesting entries of interest. These entries can be composed from multiple tables, even positing characteristics not originally planned for in the database but derivable from available evidence.

The importance of this similarity cannot be understated. When I discuss databases, I am talking about the seat of external memory and cognition for distributed cognition. Whereas other entities shape and perform input/output on the database, as well as on their own interpretation, most of the processing in a database happens through the use of business rules, either as constraints on database design or the implicit contextualization of data via queries.

Queries with regards to different realities of data, are simply structures to produce the desiderata as a function of expectations of the querent. The actual structure of the query to produce the same information varies little based on the coder’s conception of data, as there are \quotation{right} and \quotation{wrong} ways to access information in a database dictated solely by the efficiency of a particular query.

While there are techno-philosophical approaches on more sophisticated queries with their representation within the database and the methods used to construct them: mainly varying the complexity of individual queries and whether or not they the output is collated within the \quotation{host} programming language. These choices of programming and efficiency are subtly influenced by the realities of data of the programmer.

Specifically, the choice of whether or not to perform the desired operations within a purely database context or to perform intermediate stages within a programming language can certainly reflect the programmer’s conceptions of the \quotation{atomicity}\footnote{Atomicity: whether a given piece of data can be divided into associated attributes} of data. A programmer who views data as non-atomic will be more \quotation{comfortable} making giant queries as the idea of splitting apart tuples and recombining them in an extended chain does not produce a cognitive dissonance in the programmer’s mind. However, for realities of data that are less about semiotic manipulation and who consider a tuple an observed or recorded fact, intermediate translation stages within the context of a more comfortable functional programming language would necessarily appeal more: there is no violation of objectivity in operating upon retrieved data as contrasted with reformulating the presentation of that retrieved data within the data retrieval system itself.

Assuming that all three founders are sufficiently comfortable with programming languages and database systems to write queries, we can approach this from their perspective. Miss G, with her reality of data as objective representation, would prefer to retrieve numerical data gathered by automated systems and sensors. She would consider much of the ancillary data in the system to be \quotation{metadata} supporting the certainty of various conclusions that could possibly be made by manipulating the \quotation{true} data within the system.

While she recognizes the existence of text in the database, the presence of the text is considered to be merely a way to inform a website, rather than \quotation{data} to be collected and analyzed like the data she gets from sensors. Her queries would focus on data retrieval instead of manipulation, and the statistical summation and estimation necessary to make conclusions from the collected data would be performed in a sufficiently powerful mathematical system of her choice. \quotation{Tampering} with the data through sophisticated SQL queries, especially ones that filter or remove data on anything more than simple \quotation{boundary} filters (between this time period, from X sensors), would be tantamount to heresy. Removing the atomicity of the tuples in many ways invalidates the objectivity of their storage choices and recording methodologies because it is changing the context after the \quotation{experiment} (in her eyes) started.

Mr. R, as a business type, is most interested in tracking consumer sentiment over time. He also sees data as the most ephemeral, human, and subjective. Data are observations, to be sure, but the are human observations. SQL is powerful because it can produce unusual and post de facto relationships through the mechanism of queries. Mr. R is the most comfortable of the three producing \quotation{new} information through the transformative properties of queries, and sees nothing wrong with encoding a long query that touches many tables to produce a novel and interesting output. In a sense, Mr. R. would like to be able to \quotation{persuade} the database to produce the results he wants.

Mr. R is most interested in manipulating and analyzing the text as input in customer and performance reviews. Because nothing in the system is objectively true, the things which are more rich in human meaning, e.g. words, are more useful than the things which require significant statistical analysis to extract meaning from, such as numbers produced via sensor observations. The presence and analysis of the text in the database is an interesting challenge, rather than an irrelevancy.

Mrs B. is not particularly interested in the analysis of stored data. As all of this is a stored semiotic representation of human information, the primary purpose of the database is to efficiently retrieve wanted records for humans to manipulate without any incorrect or wasted retrievals. As efficiency of communications is everything and humans are necessary for transforming the data into information, Mrs. B is less interested in automated analysis and complex queries than R or G. However, she recognizes that these tasks are desirable from R and G’s standpoint and will try to design the database accordingly, creating specialized \quotation{views} (permanent queries which can be treated as tables) to suit both of their requirements. Her queries and manipulations of the database will be designed around efficiency and speed of retrieval and access rather than the semantic content of the data itself.

\section{System Models and Mental Maps}
The semiotic concept of the system model for databases\cite{Borgman1986, Storey1999} is the mental map of the designer instantiated in business rules and relationships\footnote{Relationships are specific business rules that delimit how different tuples can or cannot relate. }. The mental mapping is the functional product of the user’s internal representations of data. This map is exploring the database designer's environment, both in the explicit requirements of the system given to him by the consumer and through formal and informal observations of the old system. The designer's understanding of requirements informs the design and implementation of the intended system model.

A trivial example of a system model mismatch can be seen in the finite state machines of a typical Sydney mass-transit ride. The correct system model of a typical subway service is that the user starts by purchasing a magnetically encoded ticket, pushes it through the machine at the front, and at the destination. If there are no more uses left on the ticket, the machine captures the ticket.

However, some users may have an \quotation{insert ticket in starting machine, then discard} model in their heads, leading to problems when the inevitable ticket checks occur on a train. This confusion may be compounded by those stations that are open to the train platforms, because they are too small to justify the staff that ticket-taking stations would require. Thus, the user's actions with his or her ticket may not correspond to the {\em expected} actions by the designers of the ticket system, and from this basis, mistakes occur.

From the perspectives of the three founders of TigerWine distributors, they have been working together long enough for a shared pidgin to spring up around the database. Just as in the interviews the term \quotation{raw data} was used, the three founders would evolve similar jargon to map specific concepts within the database to their own internal realities of data. However, at the creation of the database these pieces of jargon would not have yet evolved.

One of the initial debates the three would have at the creation of the various datamarts supporting the distribution business. As the framing document states:

\startextract
TigerWine distribution business has now grown to the point that the partners would like
to begin anticipating business trends. They want to be able to predict patterns in wine
availability along with trends in wine drinking so that they can dynamically adjust their
business to maximize sales. It would be helpful for them to have a data system (warehouse
or data mart) that allows them to track changes in the products available from different
suppliers, changes in the availability of various categories of wine, and changes in the buying
habits of their customers. They would also like to analyze the efficiency of their current
business processes, especially their warehouse inventory management.

\stopextract

Miss G would be most interested in the objective and discrete changes in product availability. These are based on objective business measurements that do not require interpretation. As such, the analysis of buying habits is something of an imponderable that is a useful pipe-dream but not discoverable from the \quotation{database} they have. Data, to her, is a purchase or a price.

Mr. R is certainly interested in changes in product availability, but inasmuch as that reflects the {\em intentions} of the businesses that they are interacting with. The data warehouse being developed is a way to get inside the minds of people the business interacts with, and therefore Data is a discrete decision recorded by a computer. He would prefer more effort be spent in capturing entered text, as that provides more and better clues as to the decision making process than simple sales numbers.

Mrs. B is interested in the technical challenges of interpreting these disparate forms of human communication. As the author of the \quotation{extract, transform, and load} process, Mrs. B. will be responsible for the manipulation and transformation of the various external data sources that the data warehouse will be connected to. For her own use, she is most interested in data that is well documented, as that gives a better understanding of what the human communication is about. This documentation then allows the programs to provide better contextualization of the data for human consumption.

\section{The Consequences of Error}
The system model interprets reality into an abstract model of relationships and norms or business rules. A good system model corresponds well to reality: relationships in the map correlate with reality. The proof of a pudding is in the eating and the proof of a system map is in the using. Systems generate system maps in their user through exposed affordances. If the affordances designed into the user interface correspond with how users think they should behave, the users have a good system map.

A system model that is poorly envisioned or implemented, either because of design errors or misunderstanding of the user’s realities of data, causes multiple types of potential error\cite{Codd1990}: data corruption, data deviation, and misinterpretation. As the system map deviates from reality, the incidence of the three types of error named above becomes ever more likely.

Data corruption stems from where a system model does not allow or require sufficient updates from systems that observe reality. As parts of the system correspond to earlier realities, they increasingly fail to reflect the current reality. Errors breed. In a system where an interaction produces the right result for the wrong reason, the user does not become aware of their mistake. In fact, a mistake only occurs if there are observed secondary effects that were not desired by the user. However, further interactions may lead these second (and third) order mistakes to create their own changes to the system's state, turning what was an unnoticeable mistake into something that can bring the entire system to a screeching collapse. An example of such a problem is seen in preventative car maintenance. If a car is improperly maintained, nothing will happen initially. As systems fall out of timing, lose their lubrication, and suffer other failure-of-maintenance effects, these failures cause {\em other} systems to break down. These secondary systems {\em may} light the \quotation{idiot lights} in the dashboard, but for a bad driver, it is not until a furious boil of smoke escapes from the engine that they are confronted with their mistake. If those incidental problems are fixed without due thought, the underlying causes will simply cause {\em other} systems to fail until the car is written off as a total loss. This unfortunate outcome is purely due to the user's system model diverging from the car's reality.

The second type of error is data deviation. Whereas data corruption stems from data falling out of synchronization with reality, data deviation starts with the data being out of synchronization due to a database design that cannot accurately reflect reality. Incorrect assumptions, norms, or ignorance can lead to data deviation. I can draw a trivial example from a special case of postal mail: \quotation{general delivery} that may instruct mail to go to a centralized post office to be held for pickup. Corporate database systems may not be designed to recognize general delivery, nor may they have business rules suitable for letters addressed under general delivery notation. Geographic Information Systems have even had problems  mapping other post office special cases (Postal Boxes) to geographic location for purposes of illness tracking\cite{Hurley2003}. These problems are data deviations, in which reality does not conform to the database and errors occur when there is an irreconcilable mismatch.

Misinterpretation, on the other hand, stems from problems in Os' interpretation of tuples in the database. As the interfaces access the database, the system models of the interface designers may map the meanings of the relationships and the tables in the database incorrectly. This leads to interfaces which present the context of data incorrectly and thereby a cascading failure of meaning which eventually leads to mistake and error. 

Corruption stemming from different realities of data requires more research at this time. My research did not provide sufficient evidence to make useful specific examples of the secondary and tertiary effects described above.

The data warehouse envisioned by G, R, and B, may experience some deviation. Data deviation would stem from a mis-implemented ETL stage by Mrs. B. In this deviation, if the transformation misunderstands the reliability or meaning of the column being translated, the new column could appear correct in its new context but have its meaning shifted significantly. One probable cause of this error is misunderstood labels for financial transactions, altering the \quotation{start and stop} time periods of some transaction aggregations.

Misinterpretation in Mrs B’s data warehouse would stem from Miss G and Mr. R misunderstanding the documentation of the tables. While this looks like data deviation, the error of misunderstanding happens during data consumption rather than data recording and is a function of in-company documentation and communication practices. Because miscommunications occur when the designer fails to express her intentions correctly, it is a discrete category with different failure modes than deviation.

\section{Database as Corporate Mind}
It may even be possible to extend the new understandings of the reality of data to an exploration of the philosophy of the corporate mind, for a corporation's memory is in its databases. Donald Cunningham explains John Deely's theory of human experience when he states\cite{Cunningham1992}:

\startextract

{\em Umwelt} model and argues that our cognitive experience is mediated through a labyrinth of signs, a personal world, created by the organism via species-specific sensory characteristics and particular experiences in the physical world. This {\em umwelt} comes to define those things that we pay attention to and consider as \quotation{real.} Humans, uniquely, can create signs that go beyond immediate experience: Words, pictures, bodily movements and the like can become part of our {\em umwelt} even though they may mark objects that have no literal basis in the physical world.

\stopextract

This theory of human cognitive experience can be extended to memories. Only that information which is part of the corporate databases can be considered part of a corporation's {\em umwelt}. Although individual agents of a corporation may be aware of reality not otherwise informed by the databases, the corporate entity can only perceive reality through the inputs and outputs of its databases. This important link between the database and reality requires that the database designer's system model corresponds well with reality to reduce errors in database design.

A tragic example of the problems of corporate memory occurs in the story of the American MERS Corporation, a tiny corporation that maintains a database of most mortgages held and transferred for securitization\cite{Smith2011}.

\startextract

The implication is that MERS is superior to the local courthouse system. The evidence is the reverse. Chris Peterson has described the utterly unorthodox corporate governance system of MERS, where employees of other firms put on a MERS hat for a short period as a \quotation{MERS certifying officer} and execute documents. MERS does not supervise these individuals. Indeed, it specifically disavows any responsibility for the accuracy of MERS's records:
MERS makes no representations or warranties regarding the accuracy or reliability of the information provided. MERS disclaims responsibility or liability for errors, omissions, and the accuracy of any information provided. MERS does not input any of the information found on the MERS(r) System, but rather the MERS Members have that responsibility regarding mortgage loans in which they hold an interest.
...
And there are widespread indications of member non-compliance with MERS processes, such as making assignments without having proper corporate authorization (including out of bankrupt entities). Moreover, the updating of records by MERS members is strictly voluntary.

\stopextract

Thus, banks are using MERS as their memory; they cause it to be a model that reflects their reality. However, they have no obligation to keep the model accurate, and have no recourse or backups when problem arise because MERS is so much more efficient than the traditional paper audit trails. This conflict of priorities produces predictable results: an error-filled foreclosure process with many parties fighting over the reality of possession before courts and the U.S. congress.

To a corporation, errors in database design allow signs to be encoded into the database that do not correspond to reality. Therefore, the corporation's actions will deviate from the most optimal, because the corporation is endeavoring to solve a problem that only has a tangential relationship to reality. Poor system models beget worse system models. It is inevitable that database design passes from the initial designer to subsequent designers employed to make changes to the database.

With a poor system model, only the most glaring of errors advertise that they are errors. Other errors simply alter the corporation's responses to reality without causing agents to realize that the responses do not perfectly correspond. In the latter case, as secondary designers attempt to change the database to adapt to changing business conditions, the initial system model residing within the designer's imagination influences all subsequent system models. Without careful consideration and reflection at each stage, the errors induced by the database structure cause the database to diverge further and further from reality.

In context of the example of TigerWine Distribution, they suffer from a glaring error in their system model: wine is identified by the case, and only with difficulty as individual bottles. Because they associate wine with cases of wine, the most obvious error is that they won’t identify other opportunities to sell bottles or unusual containers of wine. The \quotation{with difficulty} above indicates that their marketing department forced through a change: promotions could contain bottles of wine as well as unusual items like corkscrews or cheese. This presents a logical disconnect within the database itself: half the company understands wine as something which comes in a case, and the other half understands wine as something that appears inside a pre-packaged promotion. While the humans involved are certainly smart enough to understand the {em nature} of a case of wine, the fact that these ontological descriptors of containers are hardcoded into the database informs the corporate identification of objects and its behavior towards them. As the technology ages and new systems are built upon the old technology, it is quite possible for these artificial divisions to be encoded in the new systems like unto laws of nature. This subsequent generation is when the \quotation{schizophrenia} sets into the corporate mind, as the databases state a thing that is simply not true in \quotation{reality} but fully accepted as true within the corporate memory.

Fixing errors in a production system is difficult as \quotation{the cost of fixing errors grows exponentially as a function of elapsed time to discovery.}\cite{Wand2002} Since these errors exist in a production system that has run for some time, the cost of fixing the errors is prohibitive at the stage when the errors are found. The only way to insure that the system model of the database designers keeps the system in line with reality is to inspect the database and insure that it corresponds with reality within the required specifications.

By understanding the impact the various users’ realities of data has on a database and on corporate memory, this philosophy of corporate mind combined with an understanding of how we conceive of data can provide tools for a data modeler to create better databases. Normal database modeling methods are quite formalized, exploring the relationship of tuples to each other and whether or not to split them into new tables. Other database design methods simply instantiate the tables of a \quotation{default} database and allow the designer to connect new tables and data structures to the pre-extant core\footnote{Django and Ruby on Rails are excellent examples of this modeling architecture.}. In many ways, most database-creation methodologies already expect the designer to understand the participants' realities.

When teaching database design, I had students create data-flow diagrams mapping the current reality. They then updated the \DFD's so that they could reflect some sort of more coherent \quotation{future reality} and created the database design from that. The process of updating designs from current reality to future reality was never explicitly spelled out, merely left as a \quotation{well, you should solve this yourself} method for the students. An understanding of the various realities of data, and especially of how different people understand data, may provide for better database design.

An understanding of data will provide for better design neither by increasing normalization\footnote{A well-accepted set of methods for removing potential errors in a database at the cost of efficiency.} nor by providing better requirements-collection methods. Instead, the discussion of realities of data will provide for better design by giving the practitioner more tools to understand the clients' requirements. Although this will not help with those clients who insist on a turnkey design, the understanding of the different realities will help render what the clients think is data into the database, including elements of data that are not currently present in the artifacts\footnote{Papers, old databases, old software systems, and the traditions and rituals of employees as manifested in things.} inspected by the database designer.

\stopcomponent
