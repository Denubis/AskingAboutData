\startcomponent c_3_survey
\product prd_Chapter3_Methodology
\project project_thesis

After the completion of the interview process, a decision to create a survey was made. The purpose of the survey would be to test two things: would it be possible to replicate the success of the interview technique in a more automated form and would the different constructions of data be evident in a more varied audience? Unfortunately, the survey suffers from both methodological and coding flaws, and is therefore presented for intellectual curiosity only. It is clearly a necessary direction for future research. One of the most critical problems is the framing of the survey, explitly asking for a differentiation between data, information, and knowledge: \quotation{This survey is exploring what you think about Data. To do that, the survey will present a list of short "scenarios". We will ask you to categorize the scenario as involving Data, Information, Knowledge, or something else, depending on your own understanding of the terms.} Unfortunately, this posits an artificial distinction between data, information, and knowledge that the participants may not originally have perceived.

During the process of collecting data, an unexpected opportunity arose: a mailing list of retired intelligence officers and agents was interested in my research. To take advantage of this opportunity, I created a survey. Optimistically, the first survey was a direct copy of the interview process, starting with a complex demographic interrogation, asking the participants to create flows and entities, and then asking them to self-direct their own investigation into their understanding of data.

It was a complete failure.

In the first survey pilot test, 18 people attempted to complete the survey. Only the person who had participated in my interviews had any idea of what the survey was talking about, and even that attempt produced no useful data. Most of the participants failed to complete the survey after taking the demographics section as an exemplar of the whole, and stalled horribly at the \quotation{now describe an entity} section.

I believe the people who attempted the survey ran into two significant problems. The first, and more critical, was the symptom known as \quotation{tl;dr} or \quotation{too long; did not read.} An associate, practiced in survey creation, suggested that no one taking a survey would read more than three sentences of instructions. As these surveys presented multiple paragraphs detailing and defining terms, it was clear that the obstacle of tl;dr was in full effect.

More subtly, though, the very abstract and theoretical nature of the questions was a problem in creating scaffolding. In the interview, because I was able to provide assistance and incremental steps according to {\em my assessment} of the participant's comprehension, I do not believe that any participant found the process exceedingly difficult. Rather, because the survey was self-guided, its impersonality was its primary point of failure. In the interest of making a survey that people could finish quickly, I had created one that was not able to adapt the scaffolding processes that made the interviews successful. Therefore, the only people to complete it were those who {\em already} knew about the concepts being discussed: one of my interview participants, and an academic who specialized in teaching the \DFD\ methodology.

From this failure, I learned that a new methodology would be required. The primary lesson was that the direct translation of interview techniques failed. My intuition was that the success of the interview was based on the feedback given by the interviewer, not the structure of the interview {\em per se}. In an online survey, people expect mostly to click answers, rather than to type essays in a web form. Very few long-answer questions are appropriate to such a format, however, and a survey comprised entirely of them is wholly inappropriate for anything but a final exam. The informal nature of a survey makes the kind of focused concentration required of long answers quite difficult, especially considering the lack of any reward besides the completion itself. It was also a mistake to establish expectations in the demographic area of the survey and then violate them on the next page through a longer theoretical component.

When considering what to include in my second attempt, I could not simply consider all the myriad ways that the first survey failed. It was also important to understand the few ways in which the first survey succeeded. The two principal successes of the first survey were in the demographic section and in the tool itself. The demographic section successfully captured interesting demographic information at a high granularity. The tool, Limesurvey, performed far beyond expectations. It is well written, database-agnostic, secure, free, and open source. The mechanism for importing and exporting surveys is streamlined and very functional.

A slavish copy of the methodology of the interview was clearly unsuccessful, and so any theme and variation on that would almost certainly share the same fate. I had to reconsider what question it was that I was trying to answer. In the first survey, the question developed into, \quotation{With a self-constructed \SDFN, can you articulate your own philosophies of data, information, and knowledge?} The respondents presented a very straightforward answer: \quotation{No.} The essence of the \SDFN\ is in the process of categorization. Although the interview length lent itself to a thorough exploration of the self-declared roles and their own data transfers, the essence of the \SDFN\ was in enticing categorization of many different, and distinct, flows.

I realized that it was possible to remove person-specific flows and allow people to classify a general set of scenarios. I wanted to explore a specific question: \quotation{How does a specific role categorize data, information, and knowledge.} The question of role was tricky, despite the success of the demographics section; the participants' answers did not suggest which role headspace they were considering their answers from. A hypothesis, while creating this, was that people would have different answers to the categories depending on the role in which they were thinking at the time-an explanation substantiated by the remarkably different interview answers one participant gave when interviewed twice about remarkably different topics. I needed to assess the person's role, rather than just his or her generalized demographics while keeping the results completely anonymous. As the scope of the prior project was in many ways its fatal flaw, minimalism was the rule of the day in the second attempt.

The survey opened with \quotation{This survey has requested that you answer it from the perspective of one of the jobs that you do. Please describe the duties of that job (in general).}. Earlier, I asked participants to: \quotation{We believe that people can have different philosophies, depending on what job they're doing. For this survey we ask that you think about the scenarios from the perspective of one of your jobs.} The phrasing of the first sentence was unfortunate, invalidating the survey’s \quotation{scientific reliability.} It is my belief that the question solicits all necessary demographic information without extending beyond the participant’s comfort zone of anonymity.

The survey questions after this point all had the same format. They would begin with: \quotation{I am trying to understand what you think of as Data, and why. The questions below ask you to categorize the scenario, and then explain the categorization. Please read the following one sentence scenario. Categorize the highlighted word or phrase in context of the scenario.}

Then the scenario is presented. Here are all the scenarios in order. The scenarios were chosen such that the highlighted phrase would help to differentiate between the three constructions of data found during the interviews. This strategy was not particularly effective.

\startitemize
\item Alice receives a letter from Bob.
\item Alice receives a letter from Bob containing instructions on how to build a machine.
\item Alice receives a letter from Bob containing a short story he has written.
\item Alice determines the locations for parts of a Rube Goldberg style machine to cook her breakfast.
\item Alice receives a letter from Bob. The letter is a time chart of what shows he has watched on TV for the last week.
\item Bob receives an e-mail from Alice, it is a record of the daily temperatures outside her apartment for the last week.
\item Bob receives a flash drive from Alice. It contains mp3 music files.
\item Bob attends a symphony with Alice and enjoys the live music.
\item Bob ignores the traffic noise outside the symphony.
\item As Bob is mugged walking home, the mugger demands his wallet and watch.
\item Charlotte finds a microfilm in a hollow coin, it contains a list of numbers and times about something unknown.
\item Charlotte finds a microfilm in a hollow coin, but cannot decipher the code.
\item Charlotte finds the secret key to the code, and realizes it’s a letter for technical support to the spy’s handlers.
\item Charlotte finds a microSD card in a hollow coin, it contains a planning program for something unknown.
\item Charlotte creates a statistical profile of a spy, to predict their actions.
\item Dave lectures to a classroom about database design.
\item Dave grades quizzes from a relational algebra course.
\item Dave discusses the reasons behind one of Eve’s incorrect answers.
\item Dave writes a survey asking people to describe their impressions of a user interface.
\item Dave saves an empty word document in preparation for his later work on a conference paper.
\item Eve writes poetry describing the winter wind.
\item Eve interviews students for the campus TV station and gets short quotes for her topic.
\item Eve looks at the weather report and decides to bring an umbrella.
\item Eve receives a letter from an ex-boyfriend, telling her to take her stuff back.
\item Frank selects which instrument readings to include in his experiment.
\item Frank designs an experiment
\stopitemize

Each of these surveys asked the participant to categorize the highlighted phrase as data, information, knowledge, or other. The other then provided a text box for elaboration. Participants were then given a large text area to explain their choice if they wished. This survey structure allowed for similar kinds of self reflection as found in the \SDFN, but did not adequately phrase the questions.


\subsection{Tools and Techniques of the Survey}

With minimalism in mind, the first survey was completely reinterpreted. The final section of the first survey, which asked people to write an essay on their own conception of data, was removed, the demographics section was reduced to one question, and the flow diagramming was reduced to simple categorization.

While people were quite willing to answer the demographic questions, as stated earlier, I feel that the initial questions distracted from and reduced peoples' attention span for the subsequent survey. The only demographic question that really matters is about the participant's mindset.

The new survey asked participants to \quotation{vividly imagine} a role, thereby artificially putting them into that role's mindset. Asking participants to engage in a specific mindset is effectively asking them to play a role: to pretend to think in ways that are foreign to their current state of mind. They retain their authentic deep expertise in the domain that they have chosen. By engaging in role-playing, participants assume the understanding of data of that role as the scenarios are filtered through the mental maps imposed by the role.

By asking participants to vividly imagine and then {\em describe} that role, the survey made it possible for them to reveal as little or as much as they wanted about their thinking methodology without disclosing potentially identifiable information. The survey gave the following instructions for the role:

\startextract
This survey is exploring what you think about Data. To do that, the survey will present a list of short scenarios. We will ask you to categorize the scenario as involving Data, Information, Knowledge, or something else, depending on your own understanding of the terms.

We believe that people can have different philosophies, depending on what job they're doing. For this survey we ask that you think about the scenarios from the perspective of one of your jobs.
\stopextract

While this was a long answer question, the fact that it came first and was asking them simply to describe what they imagined seemed to allow for it to be effective.

\placefigure[]
[fig:scenario1]
{Scenario 1 from the survey. The dropdown box asks participants to choose Data, Information, Knowledge, or other. If they choose O, a text box appears for more details.
}{\externalfigure[Chapter3/survey1.png][frame=on]}

After vividly imagining and describing a role, the survey moved into the pure measuring phase. This phase involved presentation of a one-sentence scenario with a term highlighted in bold\footnote{The full survey, in printable version, can be found in Appendix A.}. The first scenario was, \quotation{Alice receives a letter from Bob.} The survey requested: \quotation{Please read the following one sentence scenario. Categorize the highlighted word or phrase in the context of the scenario.} Participants were asked to classify via a drop-down box whether a given scenario was \quotation{Data, Information, Knowledge, or O} and, if they chose O, a text-box appeared so that they could enter their own classification. Happily, this option was often utilized, suggesting that most participants did not choose a false category of data, information, or knowledge.

When participants selected a choice from the survey, they were then encouraged to explain themselves: \quotation{Please explain in one or two sentences why you categorized the scenario that way.} This phrasing offered participants the choice to engage in as much self-reflection as they wanted about the only critical thing that mattered: the act of categorization. While it would have been desirable to have a more comprehensive survey, I feel that the second survey incorporated the lessons learned from the first and was able to produce some surprising results, regardless of its small scope.

The audience for this survey was chosen very informally from three roughly distinct groups. The first group \quotation{chosen} was from my social networks via Twitter and Facebook. This group was initially contacted to pilot test the survey. The power of social networking tools in this kind of research cannot be overstated.

As the first few results came in, the survey looked sufficiently effective at capturing the participant's understanding of data to launch it without modification. The second group consisted of the respondents to the flyer\footnote{See Appendix C.} sent to the INTELST Forum, a mailing list coordinated by the U.S. Pentagon and Army. The people who responded to the flyer were then e-mailed a link to the survey. Very little can be said about this group, save that they are all active or retired intelligence professionals from both the military and civilian side of things. The responses from this group were fascinating, and clearly reflected a personal construction of data different from that of the Os.

The third group was recruited through a presentation at the company, summarizing the findings of my interview research and inviting participants to take the survey. Unlike the more focused set of my \quotation{initial trial} group, a large subset of researchers and staff from the company was invited to my talk. This sampling allowed me to invite many distinct people to take the survey, and I feel that quite a few different jobs from the company were represented in the final results.

\stopcomponent
