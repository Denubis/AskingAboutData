\startcomponent c_3_sdfn_post
\product prd_Chapter3_Methodology
\project project_thesis

When the interview is complete, post-interview processing is relatively straightforward. The main process involved is transcribing the recordings and paper into electronic storage. With the recordings, doing so entails making backups, then processing the audio in Audacity. The diagram should be processed through Graphviz. 

The first stage is the post-processing in Audacity. Although Audacity offers a \quotation{clearvoice} option in its preference settings, I found manual manipulations to be much more useful. Recordings will routinely suffer from two problems: low dynamic range and high background noise. It is important to eliminate the noise before manipulating the dynamic range, as the volume modulations will affect the noise levels.

To reduce the noise in the recording, find a long silence, lasting five seconds or more, where neither participant is speaking. If possible, use the silence recorded at the start of the interview, but any moment of silence recorded during the interview will be acceptable. It should go without saying that the recorder must not be set to avoid recording periods of silence. Highlight the section of silence, and then choose the noise-removal effect from the effects menu. The default settings are normally acceptable, but with high-noise situations, you may want to apply the process multiple times. With the noise selected, choose the \quotation{get noise sample} button. Then, highlight the entire clip, choose noise removal again, and instruct it to remove noise. This process will take a few minutes, but will dramatically reduce the noise in the sample, at the cost of making the voices sound tinny. 

To increase the volume of the recording, a counter-intuitive practice is required. One speaker will usually be louder than the other, due to the placement of the recording device. A simple volume increase will make the voice of one speaker (usually the interviewer) intolerably loud. Normalization will also fail to have the desired effect, again because of the unusual dynamic range between the two speakers' voices. The best option I have found is the plug-in called Chris's Dynamic Compressor\footnote{http://pdf23ds.net/software/dynamic-compressor/}. With the noise removed, this plug-in serves to make both voices in a recording sound roughly the same, for a remarkable improvement in transcription quality.

\sidebar{During transcription, I made many typos. The essence of the transcription process is to aim for \quotation{good enough} quality. Although there are programs that can automatically encode aspects of meta-data of the conversation, who is speaking when and correlating it with the audio file, the most effective means of transcription I found was Google Docs, a foot pedal control for the playback device, and the program called Express Scribe. Feature-rich programs are good, but the minimal interface of Express Scribe was all that was truly necessary. Again, as this is a philosophical exploration rather than a linguistic one, transcribing every \quotation{um} and \quotation{er} is unnecessary.}

After transcription, render the hand-written \SDFN\ into a computerized visualization. While I was quite successful using Graphviz, many other programs available for many different operating systems can provide renderings of directed graphs. The important thing to note is that the program should provide for very quick data entry: it is better to have a high initial time cost in setting up regular expressions\footnote{ A regular expression is a way of programming patterns into the computer for expansion and interpretation. For details of the regular expressions used, see Appendix B.} and interpreting programs than to have to spend time rendering each individual \SDFN. Especially if there are 10 or more diagrams, creating a rendering engine can be quite effective.


\stopcomponent
