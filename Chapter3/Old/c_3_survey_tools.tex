\startcomponent c_3_survey_tools
\product prd_Chapter3_Methodology
\project project_thesis

With minimalism in mind, the first survey was completely reinterpreted. The final section of the first survey, which asked people to write an essay on their philosophy of data, was removed, the demographics section was reduced to one question, and the flow diagramming was reduced to simple categorization. 

While people were quite willing to answer the demographic questions, as stated earlier, I feel that the initial questions distracted from and reduced peoples' attention span for the subsequent survey. The only demographic question that really matters is about the participant's mindset.

The new survey asked participants to \quotation{vividly imagine} a role, thereby artificially putting them into that role's mindset. Asking participants to engage in a specific mindset is effectively asking them to play a role: to pretend to think in ways that are foreign to their current state of mind. They retain their authentic deep expertise in the domain that they have chosen. By engaging in role-playing, participants assume the philosophy of data of that role as the scenarios are filtered through the mental maps imposed by the role.

By asking participants to vividly imagine and then {\em describe} that role, the survey made it possible for them to reveal as little or as much as they wanted about their thinking methodology without disclosing potentially identifiable information. The survey gave the following instructions for the role: 

\startextract
This survey is exploring what you think about Data. To do that, the survey will present a list of short scenarios. We will ask you to categorize the scenario as involving Data, Information, Knowledge, or something else, depending on your own understanding of the terms. 

We believe that people can have different philosophies, depending on what job they're doing. For this survey we ask that you think about the scenarios from the perspective of one of your jobs.
\stopextract

While this was a long answer question, the fact that it came first and was asking them simply to describe what they imagined seemed to allow for it to be effective.

\placefigure[]
[fig:scenario1]
{Scenario 1 from the survey. The dropdown box asks participants to choose Data, Information, Knowledge, or Other. If they choose Other, a text box appears for more details. 
}{\externalfigure[Chapter3/Survey1.png][frame=on]}

After vividly imagining and describing a role, the survey moved into the pure measuring phase. This phase involved presentation of a one-sentence scenario with a term highlighted in bold\footnote{The full survey, in printable version, can be found in Appendix A.}. The first scenario was, \quotation{Alice receives a letter from Bob.} The survey requested: \quotation{Please read the following one sentence scenario. Categorize the highlighted word or phrase in the context of the scenario.} Participants were asked to classify via a drop-down box whether a given scenario was \quotation{Data, Information, Knowledge, or Other} and, if they chose other, a text-box appeared so that they could enter their own classification. Happily, this option was often utilized, suggesting that most participants did not choose a false category of data, information, or knowledge.

When participants selected a choice from the survey, they were then encouraged to explain themselves: \quotation{Please explain in one or two sentences why you categorized the scenario that way.} This phrasing offered participants the choice to engage in as much self-reflection as they wanted about the only critical thing that mattered: the act of categorization. While it would have been desirable to have a more comprehensive survey, I feel that the second survey incorporated the lessons learned from the first and was able to produce some surprising results, regardless of its small scope.

The audience for this survey was chosen very informally from three roughly distinct groups. The first group \quotation{chosen} was from my social networks via Twitter and Facebook. This group was initially contacted to pilot test the survey. The power of social networking tools in this kind of research cannot be overstated. 

As the first few results came in, the survey looked sufficiently effective at capturing the participant's philosophy of data to launch it without modification. The second group consisted of the respondents to the flyer\footnote{See Appendix C.} sent to the INTELST Forum, a mailing list coordinated by the U.S. Pentagon and Army. The people who responded to the flyer were then e-mailed a link to the survey. Very little can be said about this group, save that they are all active or retired intelligence professionals from both the military and civilian side of things. The responses from this group were fascinating, and clearly reflected a view of the philosophy of data different from that of the others.

The third group was recruited through a presentation at BlueScope Steel, summarizing the findings of my interview research and inviting participants to take the survey. Unlike the more focused set of my \quotation{initial trial} group, a large subset of researchers and staff from the company was invited to my talk. This sampling allowed me to invite many distinct people to take the survey, and I feel that quite a few different jobs from BlueScope were represented in the final results.


\stopcomponent
